<!-- Autogenerated by mlir-tblgen; don't manually edit -->
# 'mgpu' Dialect

The `mgpu` dialect models high-level multi-GPU computation.
This includes memory management, kernel launches, device synchronization, and collective communication primitives.
It uses a stream-based async execution model for parallelism.

[TOC]

## Operations

### `mgpu.all_gather` (multigpu::AllGatherOp)

_All-gather across all GPUs in a communicator_


Syntax:

```
operation ::= `mgpu.all_gather` $sendBuf `,` $recvBuf `,` $comm
              (`stream` $stream^ `:` type($stream))?
              attr-dict `:` type($sendBuf) `,` type($recvBuf) `,` type($comm)
```

Each GPU sends `sendBuf` and every GPU receives the result in `recvBuf`.
The types of the buffers must match.
GPU i's contribution appears at 
position i in the result. 

Traits: `RecursiveMemoryEffects`

#### Operands:

| Operand | Description |
| :-----: | ----------- |
| `sendBuf` | memref of any type values
| `recvBuf` | memref of any type values
| `comm` | communicator handle
| `stream` | stream handle


### `mgpu.all_reduce` (multigpu::AllReduceOp)

_All-reduce across all GPUs in a communication group_

Each GPU sends `sendBuf` and receives the result
in `recvBuf`.
`reductionKind` is the reduction operation (for example,sum, prod, 
min, max).
Send and receive buffers must have the same type, so a reduction with  (sendBuf == recvBuf) is valid.
All GPUs must  
call this operation.

Example:
```mlir
mgpu.all_reduce %send, %recv, %comm, sum
    : memref<256xf32>, memref<256xf32>, !mgpu.communicator
```

Traits: `RecursiveMemoryEffects`

#### Attributes:

<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>reductionKind</code></td><td>::mlir::multigpu::ReductionKindAttr</td><td>Reduction operation for collective operations</td></tr>
</table>

#### Operands:

| Operand | Description |
| :-----: | ----------- |
| `sendBuf` | memref of any type values
| `recvBuf` | memref of any type values
| `comm` | communicator handle
| `stream` | stream handle


### `mgpu.alloc` (multigpu::AllocOp)

_Allocate device memory_


Syntax:

```
operation ::= `mgpu.alloc` $device attr-dict `:` type($device) `->` type($ptr)
```

Allocates memory for a device.

Traits: `RecursiveMemoryEffects`

#### Operands:

| Operand | Description |
| :-----: | ----------- |
| `device` | device handle

#### Results:

| Result | Description |
| :----: | ----------- |
| `ptr` | memref of any type values


### `mgpu.broadcast` (multigpu::BroadcastOp)

_Broadcast from a GPU to all GPUs in a communicator_


Syntax:

```
operation ::= `mgpu.broadcast` $buf `,` $comm `,` $rootRank
              (`stream` $stream^ `:` type($stream))?
              attr-dict `:` type($buf) `,` type($comm)
```

The `buf` is copied to every other GPU's `buf`. All GPUs
must call this op with the same root and buffer shape.
This would usually be used to distribute model parameters, configuration data, or other 
data from a single source to all devices.
The GPU's buffer serves as the source, and all other GPUs 
receive the same data.

Traits: `RecursiveMemoryEffects`

#### Operands:

| Operand | Description |
| :-----: | ----------- |
| `buf` | memref of any type values
| `comm` | communicator handle
| `rootRank` | index
| `stream` | stream handle


### `mgpu.create_communicator` (multigpu::CreateCommunicatorOp)

_Create a communicator group for collective operations over a list of devices._


Syntax:

```
operation ::= `mgpu.create_communicator` $devices attr-dict `:` type($devices) `->` type($comm)
```

Establishes a communication group over a set of devices for collective 
operations (all_reduce, all_gather, broadcast, etc.). The ordering of 
devices determines each device's index within the communicator (first device 
is index 0, second is index 1, etc.).
All collective operations using this communicator must be called by all GPUs included in the operation.

Traits: `RecursiveMemoryEffects`

#### Operands:

| Operand | Description |
| :-----: | ----------- |
| `devices` | device handle

#### Results:

| Result | Description |
| :----: | ----------- |
| `comm` | communicator handle


### `mgpu.create_stream` (multigpu::CreateStreamOp)

_Create a new stream for a given device_


Syntax:

```
operation ::= `mgpu.create_stream` $device attr-dict `:` type($device) `->` type($stream)
```

Creates an execution stream on a device.
Streams are the mechanism provided to enable parallel execution.
Each stream maintains its own queue of operations and executes them in order, but operations on 
different streams may run in parallel.
In other words, each stream can be thought of as a separate thread of execution.
The returned stream handle must be destroyed with `mgpu.destroy_stream` when no longer needed.

Traits: `RecursiveMemoryEffects`

#### Operands:

| Operand | Description |
| :-----: | ----------- |
| `device` | device handle

#### Results:

| Result | Description |
| :----: | ----------- |
| `stream` | stream handle


### `mgpu.destroy_stream` (multigpu::DestroyStreamOp)

_Destroy a stream_


Syntax:

```
operation ::= `mgpu.destroy_stream` $stream attr-dict `:` type($stream)
```

Releases the resources associated with a stream.
All work enqueued on the stream should complete before destroying it.
Destroying a stream with pending work is invalid.

Traits: `RecursiveMemoryEffects`

#### Operands:

| Operand | Description |
| :-----: | ----------- |
| `stream` | stream handle


### `mgpu.device_config` (multigpu::DeviceConfigOp)

_Symbolic declaration of the cluster configuration_

Wraps `DeviceConfigAttr` to allow passes to do 
`SymbolTable` lookups. This op is just metadata.

Only one `mgpu.device_config` op should appear per module.

Example — 4 contiguous GPUs:
```mlir
mgpu.device_config @config #mgpu.device_config<numDevices = 4>
```
Example — 4 GPUs with specific indices:
```mlir
mgpu.device_config @config
    #mgpu.device_config<numDevices = 4, deviceIds = [0, 2, 4, 6]>
```

Traits: `AlwaysSpeculatableImplTrait`, `HasParent<::mlir::ModuleOp>`

Interfaces: `ConditionallySpeculatable`, `NoMemoryEffect (MemoryEffectOpInterface)`, `Symbol`

Effects: `MemoryEffects::Effect{}`

#### Attributes:

<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>sym_name</code></td><td>::mlir::StringAttr</td><td>string attribute</td></tr>
<tr><td><code>config</code></td><td>::mlir::multigpu::DeviceConfigAttr</td><td>device config attribute</td></tr>
</table>


### `mgpu.free` (multigpu::FreeOp)

_Free device memory_


Syntax:

```
operation ::= `mgpu.free` $ptr `,` $device attr-dict `:` type($ptr) `,` type($device)
```

Releases memory allocated for a device. The pointer must 
have been allocated on the same device.

Traits: `RecursiveMemoryEffects`

#### Operands:

| Operand | Description |
| :-----: | ----------- |
| `ptr` | memref of any type values
| `device` | device handle


### `mgpu.gather` (multigpu::GatherOp)

_Concatenate device-local shards into a single destination_


Syntax:

```
operation ::= `mgpu.gather` $dst `,` $dstDevice `,` `[` $srcBufs `]` `,` `[` $devices `]`
              (`streams` `[` $streams^ `]` `:` type($streams))?
              `axis` `=` $axis
              attr-dict `:` type($dst) `,` type($dstDevice) `,`
              `[` type($srcBufs) `]` `,` `[` type($devices) `]`
```

The opposite of `mgpu.scatter`. Copies shard buffers from multiple 
devices and combines them along `axis`. Supports uneven shards. Copies may be issued 
concurrently on the optional `streams`.

Example — gather 4x[256xf32] back into [1024xf32] on the host:
```mlir
mgpu.gather %hostBuf, %hostDev,
            %dBuf0, %dBuf1, %dBuf2, %dBuf3,
            %dev0, %dev1, %dev2, %dev3
    axis = 0
    : memref<1024xf32>, !mgpu.device,
      memref<256xf32>, memref<256xf32>, memref<256xf32>, memref<256xf32>,
      !mgpu.device, !mgpu.device, !mgpu.device, !mgpu.device
```

Traits: `AttrSizedOperandSegments`, `RecursiveMemoryEffects`

#### Attributes:

<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>axis</code></td><td>::mlir::IntegerAttr</td><td>index attribute</td></tr>
</table>

#### Operands:

| Operand | Description |
| :-----: | ----------- |
| `dst` | memref of any type values
| `dstDevice` | device handle
| `srcBufs` | memref of any type values
| `devices` | device handle
| `streams` | stream handle


### `mgpu.get_device` (multigpu::GetDeviceOp)

_Get a handle to a GPU device by index_


Syntax:

```
operation ::= `mgpu.get_device` $index attr-dict `:` type($device)
```

Returns a handle to the device at the index.
The index must be in the range [0, numDevices) specified by the `mgpu.device_config` attribute in the module.

Traits: `AlwaysSpeculatableImplTrait`

Interfaces: `ConditionallySpeculatable`, `NoMemoryEffect (MemoryEffectOpInterface)`

Effects: `MemoryEffects::Effect{}`

#### Operands:

| Operand | Description |
| :-----: | ----------- |
| `index` | index

#### Results:

| Result | Description |
| :----: | ----------- |
| `device` | device handle


### `mgpu.launch` (multigpu::LaunchOp)

_Launch a kernel on a device_

Launches a region as a kernel on the given device. The region 
body contains the kernel code that will execute on the GPU.
Directly lowered to a GPU kernel.

`grid` is the number of blocks in each dimension .
`block` is the number of threads per block.
The total number of 
threads launched is the product of grid and block.

If `stream` is provided the kernel is enqueued on that stream (async);
otherwise it executes synchronously (blocking the host until completion).

Traits: `AttrSizedOperandSegments`, `RecursiveMemoryEffects`

#### Operands:

| Operand | Description |
| :-----: | ----------- |
| `device` | device handle
| `grid` | index
| `block` | index
| `stream` | stream handle


### `mgpu.memcpy` (multigpu::MemcpyOp)

_Copy memory between devices_


Syntax:

```
operation ::= `mgpu.memcpy` $dst `,` $src `,` $dstDevice `,` $srcDevice
              (`stream` $stream^ `:` type($stream))?
              attr-dict `:` type($dst) `,` type($src) `,` type($dstDevice) `,` type($srcDevice)
```

Copies the contents of `src` to `dst`.
The source and destination memrefs should have the same element type and number of elements.
Supports copying between different devices (peer-to-peer) or 
between host and device memory.

If `stream` is provided the copy is enqueued on that stream (async);
otherwise it executes synchronously (blocking the host until the copy completes).

Traits: `RecursiveMemoryEffects`

#### Operands:

| Operand | Description |
| :-----: | ----------- |
| `dst` | memref of any type values
| `src` | memref of any type values
| `dstDevice` | device handle
| `srcDevice` | device handle
| `stream` | stream handle


### `mgpu.recv` (multigpu::RecvOp)

_Point-to-point receive_


Syntax:

```
operation ::= `mgpu.recv` $buf `,` $comm `,` $srcRank
              (`stream` $stream^ `:` type($stream))?
              attr-dict `:` type($buf) `,` type($comm)
```

Receives data from the specified source GPU into `buf`.
The buffer must have the same shape and element type as the buffer sent by the source GPU.
If the send and receive operations are not paired correctly then it will cause deadlocks.

Traits: `RecursiveMemoryEffects`

#### Operands:

| Operand | Description |
| :-----: | ----------- |
| `buf` | memref of any type values
| `comm` | communicator handle
| `srcRank` | index
| `stream` | stream handle


### `mgpu.replicate` (multigpu::ReplicateOp)

_The CPU copies a buffer to every GPU_


Syntax:

```
operation ::= `mgpu.replicate` $src `,` $srcDevice `,` `[` $devices `]` `,` `[` $dstBufs `]`
              (`streams` `[` $streams^ `]` `:` type($streams))?
              attr-dict `:` type($src) `,` type($srcDevice) `,`
              `[` type($devices) `]` `,` `[` type($dstBufs) `]`
```

The CPU copies a buffer to all target GPUs. 
All destination buffers should have the same type as `src`. 
Copies may be issued concurrently on the optional `streams`.

Example — the CPU copies a [512xf32] weight buffer to 4 GPUs:
```mlir
mgpu.replicate %weights, %hostDev,
               %dev0, %dev1, %dev2, %dev3,
               %wBuf0, %wBuf1, %wBuf2, %wBuf3
    : memref<512xf32>, !mgpu.device,
      !mgpu.device, !mgpu.device, !mgpu.device, !mgpu.device,
      memref<512xf32>, memref<512xf32>, memref<512xf32>, memref<512xf32>
```

Traits: `AttrSizedOperandSegments`, `RecursiveMemoryEffects`

#### Operands:

| Operand | Description |
| :-----: | ----------- |
| `src` | memref of any type values
| `srcDevice` | device handle
| `devices` | device handle
| `dstBufs` | memref of any type values
| `streams` | stream handle


### `mgpu.scatter` (multigpu::ScatterOp)

_Distribute a buffer evenly across multiple GPUs_


Syntax:

```
operation ::= `mgpu.scatter` $src `,` $srcDevice `,` `[` $dstBufs `]` `,` `[` $devices `]`
              (`streams` `[` $streams^ `]` `:` type($streams))?
              `axis` `=` $axis
              attr-dict `:` type($src) `,` type($srcDevice) `,`
              `[` type($dstBufs) `]` `,` `[` type($devices) `]`
```

Splits a buffer along `axis` into equal slices and copies them to 
the destination buffers on target GPUs. Requires the axis 
dimension to be divisible by the number of GPUs. Copies may be 
issued concurrently on the optional `streams`.

Example — split [1024xf32] from the host across 4 GPUs along axis 0:
```mlir
mgpu.scatter %hostBuf, %hostDev,
             %dBuf0, %dBuf1, %dBuf2, %dBuf3,
             %dev0, %dev1, %dev2, %dev3
    axis = 0
    : memref<1024xf32>, !mgpu.device,
      memref<256xf32>, memref<256xf32>, memref<256xf32>, memref<256xf32>,
      !mgpu.device, !mgpu.device, !mgpu.device, !mgpu.device
```

Traits: `AttrSizedOperandSegments`, `RecursiveMemoryEffects`

#### Attributes:

<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>axis</code></td><td>::mlir::IntegerAttr</td><td>index attribute</td></tr>
</table>

#### Operands:

| Operand | Description |
| :-----: | ----------- |
| `src` | memref of any type values
| `srcDevice` | device handle
| `dstBufs` | memref of any type values
| `devices` | device handle
| `streams` | stream handle


### `mgpu.send` (multigpu::SendOp)

_Point-to-point send_


Syntax:

```
operation ::= `mgpu.send` $buf `,` $comm `,` $dstRank
              (`stream` $stream^ `:` type($stream))?
              attr-dict `:` type($buf) `,` type($comm)
```

Sends the contents of `buf` to the specified destination GPU within the 
communication group.
The destination GPU must have a matching `mgpu.recv` operation.
If the send and receive operations are not paired correctly then it will cause deadlocks.

Traits: `RecursiveMemoryEffects`

#### Operands:

| Operand | Description |
| :-----: | ----------- |
| `buf` | memref of any type values
| `comm` | communicator handle
| `dstRank` | index
| `stream` | stream handle


### `mgpu.sharded_alloc` (multigpu::ShardedAllocOp)

_Grouped allocation for memory allocation across multiple GPUs_


Syntax:

```
operation ::= `mgpu.sharded_alloc` $devices
              `logicalShape` `=` $logicalShape
              `shardAxis` `=` $shardAxis
              `shardKind` `=` $shardKind
              attr-dict `:` type($devices) `->` type($shards)
```

Allocates one shard buffer per GPU.

Example — 4 shards of [1024x512xf32] along axis 0:
```mlir
%s0, %s1, %s2, %s3 = mgpu.sharded_alloc %dev0, %dev1, %dev2, %dev3
    logicalShape = [1024, 512] shardAxis = 0 shardKind = uniform
    : !mgpu.device, !mgpu.device, !mgpu.device, !mgpu.device
    -> memref<256x512xf32>, memref<256x512xf32>,
       memref<256x512xf32>, memref<256x512xf32>
```

Traits: `RecursiveMemoryEffects`

#### Attributes:

<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>logicalShape</code></td><td>::mlir::DenseI64ArrayAttr</td><td>i64 dense array attribute</td></tr>
<tr><td><code>shardAxis</code></td><td>::mlir::IntegerAttr</td><td>index attribute</td></tr>
<tr><td><code>shardKind</code></td><td>::mlir::multigpu::ShardKindAttr</td><td>Describes how a buffer is distributed(sharded) across GPUs</td></tr>
</table>

#### Operands:

| Operand | Description |
| :-----: | ----------- |
| `devices` | device handle

#### Results:

| Result | Description |
| :----: | ----------- |
| `shards` | memref of any type values


### `mgpu.sharded_free` (multigpu::ShardedFreeOp)

_Grouped free of GPU shard buffers_


Syntax:

```
operation ::= `mgpu.sharded_free` `[` $shards `]` `,` `[` $devices `]`
              attr-dict `:` `[` type($shards) `]` `,` `[` type($devices) `]`
```

Free the buffers allocated on the group of GPUs. Each buffer in 
`shards` is freed on the corresponding GPU in `devices`.

Example:
```mlir
mgpu.sharded_free %s0, %s1, %s2, %s3, %dev0, %dev1, %dev2, %dev3
    : memref<256x512xf32>, memref<256x512xf32>,
      memref<256x512xf32>, memref<256x512xf32>,
      !mgpu.device, !mgpu.device, !mgpu.device, !mgpu.device
```

Traits: `AttrSizedOperandSegments`, `RecursiveMemoryEffects`

#### Operands:

| Operand | Description |
| :-----: | ----------- |
| `shards` | memref of any type values
| `devices` | device handle


### `mgpu.stream_wait` (multigpu::StreamWaitOp)

_Make one stream wait on another_


Syntax:

```
operation ::= `mgpu.stream_wait` $waitingStream `,` $waitOnStreams attr-dict `:`
              type($waitingStream) `,` type($waitOnStreams)
```

Wait for all streams in `waitOnStreams` to complete.
Work submitted to `waitingStream`
after this op will not begin until all recorded work on the waited-on
streams has completed.
This enables more fine-grained synchronization rather than waiting for the entire GPU to complete.
Streams may reside on different GPUs(and it's almost expected for this dialect).

Traits: `RecursiveMemoryEffects`

#### Operands:

| Operand | Description |
| :-----: | ----------- |
| `waitingStream` | stream handle
| `waitOnStreams` | stream handle


### `mgpu.sync_device` (multigpu::SyncDeviceOp)

_Synchronize on a GPU_


Syntax:

```
operation ::= `mgpu.sync_device` $device attr-dict `:` type($device)
```

Blocks the host until all work submitted to a GPU
has completed.
This operation waits for all work submitted on a GPU to complete.
Use `mgpu.sync_stream` to synchronize individual streams.

Traits: `RecursiveMemoryEffects`

#### Operands:

| Operand | Description |
| :-----: | ----------- |
| `device` | device handle


### `mgpu.sync_stream` (multigpu::SyncStreamOp)

_Synchronize a single stream_


Syntax:

```
operation ::= `mgpu.sync_stream` $stream attr-dict `:` type($stream)
```

Blocks the host until all work submitted to a stream has completed.

Traits: `RecursiveMemoryEffects`

#### Operands:

| Operand | Description |
| :-----: | ----------- |
| `stream` | stream handle


### `mgpu.terminator` (multigpu::TerminatorOp)

_Terminator for mgpu.launch regions_


Syntax:

```
operation ::= `mgpu.terminator` attr-dict
```

A terminator for the region of a `mgpu.launch`.
The region returns no values.

Traits: `AlwaysSpeculatableImplTrait`, `HasParent<LaunchOp>`, `Terminator`

Interfaces: `ConditionallySpeculatable`, `NoMemoryEffect (MemoryEffectOpInterface)`

Effects: `MemoryEffects::Effect{}`


### `mgpu.uneven_scatter` (multigpu::UnevenScatterOp)

_Distribute a buffer across devices with asymmetric slice sizes_


Syntax:

```
operation ::= `mgpu.uneven_scatter` $src `,` $srcDevice `,` `[` $dstBufs `]` `,` `[` $devices `]`
              (`streams` `[` $streams^ `]` `:` type($streams))?
              `sliceSizes` `=` $sliceSizes `axis` `=` $axis
              attr-dict `:` type($src) `,` type($srcDevice) `,`
              `[` type($dstBufs) `]` `,` `[` type($devices) `]`
```

Similar to `mgpu.scatter`, but the size of data to be distributed to each GPU is specified. 
Copies may be issued concurrently on the optional `streams`.

Example — partition [100xf32] across 3 GPUs as [34, 33, 33]:
```mlir
mgpu.uneven_scatter %src, %srcDev,
                    %dBuf0, %dBuf1, %dBuf2,
                    %dev0, %dev1, %dev2
    sliceSizes = [34, 33, 33] axis = 0
    : memref<100xf32>, !mgpu.device,
      memref<34xf32>, memref<33xf32>, memref<33xf32>,
      !mgpu.device, !mgpu.device, !mgpu.device
```

Traits: `AttrSizedOperandSegments`, `RecursiveMemoryEffects`

#### Attributes:

<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>sliceSizes</code></td><td>::mlir::DenseI64ArrayAttr</td><td>i64 dense array attribute</td></tr>
<tr><td><code>axis</code></td><td>::mlir::IntegerAttr</td><td>index attribute</td></tr>
</table>

#### Operands:

| Operand | Description |
| :-----: | ----------- |
| `src` | memref of any type values
| `srcDevice` | device handle
| `dstBufs` | memref of any type values
| `devices` | device handle
| `streams` | stream handle


## Attributes

### DeviceConfigAttr

Compile-time GPU configuration for the module (at the moment, just the number of GPUs and their IDs)

Syntax:

```
#mgpu.device_config<
  uint32_t,   # numDevices
  DenseI32ArrayAttr   # deviceIds
>
```

A structured attribute recording the GPU cluster configuration known at 
compile time. 

Fields:
- `numDevices`: The total count of GPUs available.
- `deviceIds`: Optional explicit physical device indices for non-contiguous 
  sets (e.g., [0, 2, 4, 6]).

Passes retrieve this info through the `mgpu.device_config` symbol op.

Example — 4 contiguous GPUs:
```mlir
#mgpu.device_config<numDevices = 4>
```
Example — 4 GPUs with specific indices:
```mlir
#mgpu.device_config<numDevices = 4, deviceIds = [0, 2, 4, 6]>
```

#### Parameters:

| Parameter | C++ type | Description |
| :-------: | :-------: | ----------- |
| numDevices | `uint32_t` |  |
| deviceIds | `DenseI32ArrayAttr` |  |

## Types

### CommunicatorType

A group of devices that can be used for collective communication operations

Syntax: `!mgpu.communicator`



### DeviceType

An opaque handle to a GPU device

Syntax: `!mgpu.device`



### StreamType

An opaque handle to a device stream

Syntax: `!mgpu.stream`



## Enums

### ReductionKind

Reduction operation for collective operations

#### Cases:

| Symbol | Value | String |
| :----: | :---: | ------ |
| Sum | `0` | sum |
| Prod | `1` | prod |
| Min | `2` | min |
| Max | `3` | max |

### ShardKind

Describes how a buffer is distributed(sharded) across GPUs

#### Cases:

| Symbol | Value | String |
| :----: | :---: | ------ |
| Uniform | `0` | uniform |
| Uneven | `1` | uneven |
| Replicate | `2` | replicate |

